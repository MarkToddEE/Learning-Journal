
# Building a Data driven Culture
1. Build Relationships for engagement with key stakeholders
2. Transparency in Algorithms
   - Simplify complex models & educate on function initially to gain acceptance
3. Celebrate & embrace small wins
   - Wins can prove value and persuade sceptical stakeholders of worth
4. Raise Data literacy
  - pivotal for sustained adoption of a data-driven culture
  - equips personnel with the requisite skills to navigate data-related endeavours effectively
  - Support for additional training comes from demonstrating value from small wins
# Transitioning to Big Data
1. Reasons
  - Inadequate current tools for increase in volume of data
  - Current systems struggle to process the volume of data
  - Missed opportunities to use the increased volume and breadth of data to analyse and predict
2. Definitions
  - Not just about volume but also approach to collection, processing and use
  - Big Data
    - like an ocean, vast with unexplored areas
  - Small Data
    - Lake, crystal clear, smaller and easier to navigate

  >  In our modern, data-driven world, understanding the difference between these two types of data is crucial. 
It's not just about the amount of data we're dealing with but also about the tools, techniques, and strategies we use to handle it. 
Whether it's a small business analysing customer feedback (Small Data) or a multinational corporation processing millions of transactions per day (Big Data), the way we approach these datasets can have a profound impact on our insights and decisions.
# Data Characteristics - 5 V's of Big Data
1. Volume
   - typically terabytes and above, challenges to storage and processing
2. Variety
   - types, sources, structured, unstructured, semi structured, different formats
3. Velocity
   - speed of collection, generated and processed. Often streamed from various sources requiring real (or near real) time processing
4. Veracity
   - reliability, trustworthiness and accuracy. Often contains noisy, incomplete or erroeous data. Significant challenge
5. Value
   - Potential insights and benefits through advanced analytics, predictive modelling, and data-driven decision-making. 
# Fundamentals of Data
1. Volume
  - Byte (B) - 8 bits - single character
  - Kilobyte (KB) 1024 Bytes - short paragraph
  - Megabyte (MB) 1024 KB - ~ 43 3 page word documents
  - Gigabyte (GB) 1024 GB - 20 minute DVD
  - Terabyte (TB) - 1024 GB
  - Petabyte (PB) - 1024 TB - 13.3 yrs HD Video/ 250000 humans DNA
  - Exabyte (EB) - 1024 PB - 5 yrs of internet traffic
  - Zettabyte (ZB)
  - Yottabyte (YB)
2. Types
  - Binomial - One of 2 values
  - Nominal - Named data eg countries, colours. Segmentation or categorisation
  - Ordinal - has an order eg small, medium, large
  - Qualitative - anything not described as a number
  - Quantitative - anything described as a number
  - Discrete - Anything that can be counted
  - Continuous - Anything that is measured eg weight, height, distance, time 
3. External Data
  - Open & Public - Government published dat such as census data
  - Administrative Data - Data collected by organisations for operational purposes, record keeping or to track performance.
  - Research Data - Data collected through studies, experiments, surveys, observations for research purposes.
  - External data - Third-party data providers sell access to compiled data sets from various sources
  - Open and Public - https://datasetsearch.research.google.com

# Standards and engineering best practices
1. Data Formats
   - JSON - lightweight, human-readable format for transmitting data between servers and web applications, enhancing user experiences and performance.
   - CSV - format for storing tabular data, facilitating efficient financial management and reporting processes.
   - XML - XML is a markup language for structuring and exchanging data between systems, promoting interoperability
2. API standards.
   - APIs are the foundational building blocks enabling interconnected digital systems and data exchange 
   - RESTful API - All components of a RESTful API have to follow the same rules to communicate with each other. This also makes it easier to understand interactions between the various components of a system https://www.seobility.net/en/wiki/REST_API
   - OpenAPI - This term refers to the standard specification for building and documenting RESTful APIs, accelerating development cycles and enhancing collaboration.
   - Adopting OpenAPI specifications will standardise API's offering richer ecosystem
3. Cloud computing standards
   - AWS Well-architected framework
   - Azure Well-architected framework - provides guidance for building cloud solutions on Microsift Azure
4. Regulatory requirements
   - GDPR EU regulation governing data & privacy
   - ISO 27001 crucial for ensuring the confidentiality, integrity, and availability of data and information assets.
5. Data stewardship principles
   - Data quality - Ensuring accuracy and reliability for informed decision-making
   - Data governance - Establishing policies for managing data assets throughout their lifecycle
   - Data ethics - Adhering to ethical guidelines for responsible data usage
6. Engineering best practice
   - Scalability - Strategies for handling growing data volumes without sacrificing performance, benefiting e-commerce platforms during peak traffic.
   - Reliability - Implementing redundancy and disaster recovery mechanisms, safeguarding patient data in healthcare information systems.
   - Security - Employing encryption and access controls to protect sensitive financial data, ensuring compliance with regulatory standards.
   - Performance Optimisation - Techniques for improving data delivery and system efficiency, enhancing user experiences in content delivery networks.
   - Data Documentation - documenting data pipelines and system configurations, facilitating collaboration and troubleshooting in software development projects.

# Working with Various Data types
1. Data Collection
2. Data cleaning
3. Data transformation
4. Data integration

   - Python & Pandas - software library written for Python
   - SQL - QL is primarily used for querying databases to retrieve specific information or perform operations such as data manipulation, data definition, data control, and data management.
   - Power BI - provides interactive visualisations and business intelligence capabilities with a simple interface for creating and sharing reports and dashboards.
   - Tableu - Tableau offers drag-and-drop functionality to create dynamic and interactive visualisations, making it easy for users to explore and understand data insights.
6. Databses

# Data Science Hierarchy of needs
![image](https://github.com/user-attachments/assets/e99bdff7-e355-4efa-8038-1cc545d9944a)

# Turning data into actionable insight
![image](https://github.com/user-attachments/assets/8e9acf4d-612a-412c-9b66-08aadb17f8fd)

# Summary
   - There are two main categories of data types: qualitative (nominal, ordinal, binomial) and quantitative (discrete, continuous)
   - Data is measured using standardised units ranging from bits to yottabytes, with each larger unit being 1,024 times bigger than the previous one
   - Important technological standards for data engineering include data formats like JSON, CSV, XML, API standards like REST and OpenAPI Specification, and cloud computing standards like AWS Well-Architected Framework
   - Key regulations governing data include GDPR for data privacy, HIPAA for healthcare data security, and CCPA for consumer privacy rights
   - The three fundamental principles of data stewardship are data quality, data governance, and data ethics
   - Engineering best practices for data systems include scalability, reliability, security, performance optimisation, and documentation
   - The data management lifecycle involves collecting data from sources, cleaning/transforming data, integrating datasets, and visualising insights using tools like SQL, Power BI, and Tableau
   - Combining internal data with external open data, administrative data, research data, and third-party sources enriches insights for better decision-making



   
   
